{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# This is a file where we show how we setup the dataset\n","This process has been done on local, since loading thousands of audio tracks on drive wasn't feasible. We setup the dataset and directly loaded the images to use on colab."],"metadata":{"id":"lhl9ovcNeZON"}},{"cell_type":"markdown","source":["In this file the data is loaded on an initial sample of 1000 tracks for both classes. \\\\\n","The final project uses 3000 tracks for each class.\n"],"metadata":{"id":"w70JnDq3em5d"}},{"cell_type":"markdown","source":["The result of this process is the images dataset. \\\\\n","This file saves the data inside \"./dataset\". \\\\\n","The final dataset is inside \"./6k_samples_dataset\""],"metadata":{"id":"trtThcF9e4OJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKiBuu-Q7uQa"},"outputs":[],"source":["from google.colab import drive"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"nZ6Hv8Sf79Cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733412093277,"user_tz":-60,"elapsed":20984,"user":{"displayName":"matteo sorrentini","userId":"11960664345585689766"}},"outputId":"cc4a32f4-5b47-440c-cfa6-0f1373c40d10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Homeworks FDS/Progetto"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUQsZXXDMRuW","executionInfo":{"status":"ok","timestamp":1733412377140,"user_tz":-60,"elapsed":207,"user":{"displayName":"matteo sorrentini","userId":"11960664345585689766"}},"outputId":"cbf7ec20-e671-4215-fbd1-582228613f28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1Vzw8m8Ha_VscaXjjIlDjZrQtp1m45M3N/Homeworks FDS/Progetto\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4pv4sV2MbT1","executionInfo":{"status":"ok","timestamp":1733412380317,"user_tz":-60,"elapsed":227,"user":{"displayName":"matteo sorrentini","userId":"11960664345585689766"}},"outputId":"cd1fb0b8-dca9-4098-8d87-5f2f3348b96e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34maam-cropped\u001b[0m/  \u001b[01;34mdataset\u001b[0m/  dataset_setup.ipynb  \u001b[01;34mfma_small_cropped\u001b[0m/\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","\n","import os\n","import random\n","import shutil\n","import IPython.display as ipd\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn as skl\n","import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n","import librosa\n","import librosa.display\n","\n","plt.rcParams['figure.figsize'] = (17, 5)"],"metadata":{"id":"y2DUxHwJ91C4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save 1000 natural tracks"],"metadata":{"id":"opBfa-T1-bR0"}},{"cell_type":"markdown","source":["From the total dataset inside \"./fma_small\" folder, containing 8000 tracks, we randomly selected 1000 on them (3000 for the final dataset), and put them inside \"./fma_small_cropped\"."],"metadata":{"id":"UDoUXE5XfpzN"}},{"cell_type":"code","source":["source_dir = './fma_small'\n","target_dir = './fma_small_cropped'\n","num_files = 1000\n","\n","if not os.path.exists(target_dir):\n","    os.makedirs(target_dir)\n","else:\n","    shutil.rmtree(target_dir)\n","    os.makedirs(target_dir)\n","\n","selected_tracks = []\n","for subfolder in os.listdir(source_dir):\n","    sub_path = os.path.join(source_dir, subfolder)\n","    if os.path.isdir(sub_path):\n","        for track in os.listdir(sub_path):\n","            track_path = os.path.join(sub_path, track)\n","            selected_tracks.append(track_path)\n","\n","selected_tracks = random.sample(selected_tracks, num_files)\n","\n","for track in selected_tracks:\n","    shutil.copy(track, target_dir)\n","\n","print(f\"selected {len(selected_tracks)} files and copied them to {target_dir}\")"],"metadata":{"id":"NVmdjvjj-ALn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Crop the artificial tracks at random 30s segments"],"metadata":{"id":"77tNkEoc-dsr"}},{"cell_type":"markdown","source":["From the total artificial dataset inside \"./0001-1000-audio-mixes\" folder, containing 1000 tracks (3000 for the final datset), we selected a random 30 seconds segmens from each of them and saved into \"./aam-cropped\"."],"metadata":{"id":"THBWxR0zguoo"}},{"cell_type":"code","source":["!pip install pydub"],"metadata":{"id":"Qmu8ali7-irB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733412432359,"user_tz":-60,"elapsed":3999,"user":{"displayName":"matteo sorrentini","userId":"11960664345585689766"}},"outputId":"6469a81c-973e-41ba-ec94-33c3e98093ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["from pydub import AudioSegment\n","\n","source_dir = './0001-1000-audio-mixes'\n","target_dir = './aam-cropped'\n","\n","if not os.path.exists(target_dir):\n","    os.makedirs(target_dir)\n","else:\n","    shutil.rmtree(target_dir)\n","    os.makedirs(target_dir)\n","\n","segment_duration = 30 * 1000\n","\n","for track in os.listdir(source_dir):\n","    track_path = source_dir + '/' + track\n","    try:\n","        audio = AudioSegment.from_file(track_path, format='flac')\n","\n","        if len(audio) > segment_duration:\n","            start = random.randint(0, len(audio) - segment_duration)\n","            end = start + segment_duration\n","\n","            segment = audio[start:end]\n","            segment.export(os.path.join(target_dir, track), format='wav')\n","        else:\n","            audio.export(os.path.join(target_dir, track), format='wav')\n","    except Exception as e:\n","        print(f\"error processing {track_path}: {e}\")\n","\n","print(f\"processed {len(os.listdir(target_dir))} files and copied them to {target_dir}\")"],"metadata":{"id":"gPVa8KS7-dM_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset creation"],"metadata":{"id":"ivnINnfj-nEJ"}},{"cell_type":"markdown","source":["### Process each track, generate the spectrogram and save the images into \"./dataset\" (6k_samples_dataset for the final dataset)."],"metadata":{"id":"d9ikvdjD-q1Y"}},{"cell_type":"code","source":["def save_spectrogram_image(filename, save_dir, label):\n","    x, sr = librosa.load(filename, sr=None, mono=True)\n","\n","    stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n","\n","    mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n","    log_mel = librosa.amplitude_to_db(mel)\n","\n","    plt.figure(figsize=(10, 4))\n","    librosa.display.specshow(log_mel, sr=sr, x_axis='time', y_axis='mel', hop_length=512)\n","    plt.axis('off')\n","\n","    base_name = os.path.splitext(os.path.basename(filename))[0]\n","    save_path = os.path.join(save_dir, f\"{label}_{base_name}.png\")\n","\n","    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n","    plt.close()\n","\n","    return save_path"],"metadata":{"id":"Yyt-1fvy-l9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_dataset(audio_dir, save_dir, label):\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    for track in os.listdir(audio_dir):\n","        track_path = os.path.join(audio_dir, track)\n","        save_spectrogram_image(track_path, save_dir, label)\n","\n","    print(f\"processed {len(os.listdir(save_dir))} files and saved them to {save_dir}\")"],"metadata":{"id":"LXhehe_O-wvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["process_dataset('./fma_small_cropped', './dataset/natural', label=1)\n","process_dataset('./aam-cropped', './dataset/artificial', label=0)"],"metadata":{"id":"sEaVLzQt-ymr"},"execution_count":null,"outputs":[]}]}